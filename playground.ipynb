{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93db8667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (0.8.6)\n",
      "Requirement already satisfied: google-genai in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.60.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (5.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (2.20.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (2.29.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (2.188.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (2.47.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (2.10.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 1)) (1.27.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai->-r requirements.txt (line 1)) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 1)) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 1)) (1.71.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 1)) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai->-r requirements.txt (line 1)) (2026.1.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (4.12.1)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (9.0.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai->-r requirements.txt (line 1)) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (4.57.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (0.36.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (3.17.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers->-r requirements.txt (line 4)) (2025.3.2)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tqdm->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tf-keras->-r requirements.txt (line 8)) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.5.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.0.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 1)) (0.31.2)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 1)) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc0b7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import google.genai as genai\n",
    "from google.genai import types\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import typing_extensions as typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d53ecdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SETUP & CONFIGURATION\n",
    "# ------------------------\n",
    "load_dotenv()  # Load API key from .env file\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc3d58e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model\n"
     ]
    }
   ],
   "source": [
    "# Load the local embedding model (Free, runs on your laptop)\n",
    "# This handles \"Stage 3: Ranking\"\n",
    "print(\"Loading embedding model\")\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68bb88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the strict structure for the LLM output (Stage 1)\n",
    "# This forces Gemini to return valid JSON every time.\n",
    "class ConstraintSchema(typing.TypedDict):\n",
    "    category: str | None\n",
    "    temperature: str | None\n",
    "    max_calories: int | None\n",
    "    max_sugar: int | None\n",
    "    max_price: float | None\n",
    "    dairy_free: bool | None\n",
    "    vegan: bool | None\n",
    "    caffeine_level: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fefe32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# 2. LOAD DATA\n",
    "# ------------\n",
    "# We use pandas to read the CSV files\n",
    "try:\n",
    "    df_products = pd.read_csv('data/products.csv')\n",
    "    # START WITH TRAINING DATA to test your logic. \n",
    "    # Once it works, switch this filename to 'queries_test.csv' for the final run.\n",
    "    df_queries = pd.read_csv('data/queries_train.csv') \n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV files not found. Please check your 'data' folder.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28ac25e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating product embeddings...\n",
      "Product embeddings ready.\n"
     ]
    }
   ],
   "source": [
    "# 3. PRE-COMPUTE PRODUCT EMBEDDINGS\n",
    "# ---------------------------------\n",
    "# We turn every product into a math vector now so we don't have to do it later.\n",
    "print(\"Generating product embeddings...\")\n",
    "df_products['embedding_text'] = (\n",
    "    df_products['name'].fillna('') + \" \" + \n",
    "    df_products['description'].fillna('') + \" \" + \n",
    "    df_products['category'].fillna('')\n",
    ")\n",
    "product_embeddings = embedder.encode(df_products['embedding_text'].tolist())\n",
    "print(\"Product embeddings ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fae06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. STAGE 1: CONSTRAINT EXTRACTION (Using Gemini)\n",
    "# ------------------------------------------------\n",
    "from sklearn import exceptions\n",
    "\n",
    "def extract_constraints_gemini(query_text):\n",
    "    \"\"\"\n",
    "    Sends the user query to Gemini 2.5 Flash and asks for a JSON response.\n",
    "    \"\"\"\n",
    "    # FIX 1: Add this loop so 'continue' has somewhere to go\n",
    "    while True:\n",
    "        prompt = f\"\"\"\n",
    "        You are a Starbucks Data Assistant. Extract search constraints from this query:\n",
    "        Query: \"{query_text}\"\n",
    "        \n",
    "        Return a JSON object with these exact keys. If a constraint is not mentioned, use null.\n",
    "        - category: \"espresso\", \"brewed\", \"cold_brew\", \"frappuccino\", \"refresher\", \"tea\" or null\n",
    "        - temperature: \"hot\", \"iced\", \"blended\" or null\n",
    "        - max_calories: number or null\n",
    "        - max_sugar: number (grams) or null\n",
    "        - max_price: number or null\n",
    "        - dairy_free: true (if \"no milk\", \"dairy free\") or null\n",
    "        - vegan: true (if \"vegan\", \"plant based\") or null\n",
    "        - caffeine_level: \"none\", \"low\", \"medium\", \"high\" or null\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash\",\n",
    "                contents=prompt,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=ConstraintSchema \n",
    "                )\n",
    "            )\n",
    "            # SUCCESS: Parse and return\n",
    "            parsed = json.loads(response.text)\n",
    "\n",
    "            # Sleep 4s ensures we stay under the 15 RPM limit safely\n",
    "            time.sleep(4)\n",
    "            return parsed\n",
    "        \n",
    "        # FIX 2: Catch generic exceptions and check the message for \"429\" or \"Quota\"\n",
    "        # This is safer than importing specific exception libraries that might conflict.\n",
    "        except Exception as e:\n",
    "            error_msg = str(e).lower()\n",
    "            if \"429\" in error_msg or \"quota\" in error_msg or \"resource_exhausted\" in error_msg:\n",
    "                print(f\"‚ö†Ô∏è Quota hit! Sleeping 60s...\")\n",
    "                time.sleep(60)\n",
    "                continue # Now this works because it's inside 'while True'\n",
    "            else:\n",
    "                # Real error? Stop and return empty.\n",
    "                print(f\"‚ùå Extraction Error: {e}\")\n",
    "                return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc48bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. STAGE 2: FILTERING\n",
    "# ---------------------\n",
    "def filter_products(products_df, constraints):\n",
    "    \"\"\"\n",
    "    Removes products that violate the specific constraints found by Gemini.\n",
    "    \"\"\"\n",
    "    filtered = products_df.copy()\n",
    "    \n",
    "    # Text Filters\n",
    "    if constraints.get('category'):\n",
    "        filtered = filtered[filtered['category'] == constraints['category']]\n",
    "    if constraints.get('temperature'):\n",
    "        filtered = filtered[filtered['temperature'] == constraints['temperature']]\n",
    "        \n",
    "    # Number Filters (Using <= for max limits)\n",
    "    if constraints.get('max_calories'):\n",
    "        filtered = filtered[filtered['calories'] <= constraints['max_calories']]\n",
    "    if constraints.get('max_sugar'):\n",
    "        filtered = filtered[filtered['sugar_g'] <= constraints['max_sugar']]\n",
    "    if constraints.get('max_price'):\n",
    "        filtered = filtered[filtered['price'] <= constraints['max_price']]\n",
    "        \n",
    "    # Boolean Filters\n",
    "    if constraints.get('dairy_free'):\n",
    "        filtered = filtered[filtered['contains_dairy'] == False]\n",
    "    if constraints.get('vegan'):\n",
    "        filtered = filtered[filtered['is_vegan'] == True]\n",
    "    \n",
    "    # Caffeine Filter (Simple Mapping)\n",
    "    if constraints.get('caffeine_level'):\n",
    "        level = constraints['caffeine_level']\n",
    "        if level == 'none':\n",
    "            filtered = filtered[filtered['caffeine_mg'] < 5]\n",
    "        elif level == 'high':\n",
    "            filtered = filtered[filtered['caffeine_mg'] > 150]\n",
    "            \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "037e5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. STAGE 3: RANKING\n",
    "# -------------------\n",
    "def rank_products(query_text, candidate_df):\n",
    "    \"\"\"\n",
    "    Sorts the remaining products by how similar they are to the user query.\n",
    "    \"\"\"\n",
    "    if candidate_df.empty:\n",
    "        return []\n",
    "    \n",
    "    # 1. Encode the user's query into a vector\n",
    "    query_vec = embedder.encode([query_text])\n",
    "    \n",
    "    # 2. Get the vectors for ONLY the valid candidates\n",
    "    # (We use the dataframe index to grab the correct pre-computed vectors)\n",
    "    candidate_vectors = product_embeddings[candidate_df.index]\n",
    "    \n",
    "    # 3. Calculate similarity scores\n",
    "    scores = cosine_similarity(query_vec, candidate_vectors)[0]\n",
    "    \n",
    "    # 4. Attach scores and sort\n",
    "    candidate_df = candidate_df.copy()\n",
    "    candidate_df['score'] = scores\n",
    "    ranked = candidate_df.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    return ranked['product_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e15fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 7/100 [00:41<09:03,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Quota hit! Sleeping 60s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 17/100 [02:38<09:13,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Quota hit! Sleeping 60s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 18/100 [03:44<33:42, 24.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Quota hit! Sleeping 60s...\n",
      "‚ö†Ô∏è Quota hit! Sleeping 60s...\n",
      "‚ö†Ô∏è Quota hit! Sleeping 60s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 18/100 [06:52<31:19, 22.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m q_text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# A. Extract (Wait 10 seconds to respect Free Tier limits)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m constraints \u001b[38;5;241m=\u001b[39m extract_constraints_gemini(q_text)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# B. Filter\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# CRITICAL FIX: Check if constraints exist before filtering\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m constraints:\n",
      "Cell \u001b[1;32mIn[31], line 39\u001b[0m, in \u001b[0;36mextract_constraints_gemini\u001b[1;34m(query_text)\u001b[0m\n\u001b[0;32m     36\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Sleep 4s ensures we stay under the 15 RPM limit safely\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# FIX 2: Catch generic exceptions and check the message for \"429\" or \"Quota\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# This is safer than importing specific exception libraries that might conflict.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 7. MAIN EXECUTION LOOP\n",
    "# ----------------------\n",
    "results = []\n",
    "print(f\"Processing {len(df_queries)} queries...\")\n",
    "\n",
    "# Loop through every query in the CSV\n",
    "for i, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "    q_id = row['query_id']\n",
    "    q_text = row['query_text']\n",
    "    \n",
    "    # A. Extract (Wait 10 seconds to respect Free Tier limits)\n",
    "    constraints = extract_constraints_gemini(q_text)\n",
    "    \n",
    "    # B. Filter\n",
    "    # CRITICAL FIX: Check if constraints exist before filtering\n",
    "    if constraints:\n",
    "        candidates = filter_products(df_products, constraints)\n",
    "    else:\n",
    "        # If extraction failed, treat it as \"no constraints\" (search everything)\n",
    "        candidates = df_products\n",
    "    \n",
    "    # Fallback: If filtering kills everything, ignore filters and rank everything\n",
    "    if candidates.empty:\n",
    "        candidates = df_products\n",
    "        \n",
    "    # C. Rank\n",
    "    ranked_ids = rank_products(q_text, candidates)\n",
    "    \n",
    "    # D. Save Result\n",
    "    results.append({\n",
    "        \"query_id\": q_id,\n",
    "        \"products\": \";\".join(ranked_ids)  # Format: ID1;ID2;ID3\n",
    "    })\n",
    "\n",
    "    # Convert to DataFrame and view\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"‚úÖ Done!\")\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c353d6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! File saved to output/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# 8. EXPORT FINAL CSV\n",
    "# -------------------\n",
    "submission = pd.DataFrame(results)\n",
    "submission.to_csv('output/submission.csv', index=False)\n",
    "print(\"Success! File saved to output/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d66fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key loaded: ...gIDY8\n",
      "\n",
      "--- TEST 1: Basic Connection ---\n",
      "‚úÖ Success: Hello V2!\n",
      "\n",
      "--- TEST 2: JSON Extraction ---\n",
      "‚úÖ Parsed Data: {'category': 'latte', 'price': 4.5, 'is_hot': True}\n",
      "üöÄ SYSTEM READY: JSON parsing is working perfectly.\n"
     ]
    }
   ],
   "source": [
    "# 1. ENSURE LIBRARY IS INSTALLED\n",
    "# If you get an import error, uncomment the line below and run it:\n",
    "# %pip install -U google-genai\n",
    "\n",
    "import os\n",
    "from google import genai\n",
    "from pydantic import BaseModel, TypeAdapter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 2. SETUP CLIENT\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"‚ùå Error: .env file not found or empty. Please check your key.\")\n",
    "else:\n",
    "    print(f\"Key loaded: ...{api_key[-5:]}\")\n",
    "    client = genai.Client(api_key=api_key)\n",
    "\n",
    "    # 3. DEFINE SCHEMA (The new way uses Pydantic or Dicts easily)\n",
    "    # We will use a standard dict for simplicity here, similar to your TypedDict\n",
    "    schema_config = {\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_schema\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"category\": {\"type\": \"STRING\"},\n",
    "                \"price\": {\"type\": \"NUMBER\"},\n",
    "                \"is_hot\": {\"type\": \"BOOLEAN\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"\\n--- TEST 1: Basic Connection ---\")\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\", \n",
    "            contents=\"Say 'Hello V2!'\"\n",
    "        )\n",
    "        print(f\"‚úÖ Success: {response.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection Failed: {e}\")\n",
    "\n",
    "    print(\"\\n--- TEST 2: JSON Extraction ---\")\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=\"Find me a hot latte for $4.50\",\n",
    "            config=schema_config\n",
    "        )\n",
    "        \n",
    "        # In V2, response.parsed automatically converts it to a dict/object!\n",
    "        print(f\"‚úÖ Parsed Data: {response.parsed}\")\n",
    "        \n",
    "        if response.parsed['price'] == 4.5:\n",
    "            print(\"üöÄ SYSTEM READY: JSON parsing is working perfectly.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå JSON Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf993f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
