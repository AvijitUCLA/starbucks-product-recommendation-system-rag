{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0582221f",
   "metadata": {},
   "source": [
    "### Installing requried libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "93db8667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (0.8.6)\n",
      "Requirement already satisfied: google-genai in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.60.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (5.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (1.8.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: tf-keras in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (2.20.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (2.29.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (2.188.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (2.47.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (5.29.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (2.10.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 1)) (1.27.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai->-r requirements.txt (line 1)) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 1)) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 1)) (1.71.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 1)) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai->-r requirements.txt (line 1)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai->-r requirements.txt (line 1)) (2026.1.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (4.12.1)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (9.0.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai->-r requirements.txt (line 1)) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (4.57.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (0.36.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (3.17.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers->-r requirements.txt (line 4)) (2025.3.2)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tqdm->-r requirements.txt (line 7)) (0.4.6)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tf-keras->-r requirements.txt (line 8)) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.5.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (3.0.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 1)) (0.31.2)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 1)) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\avijit\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras->-r requirements.txt (line 8)) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "dc0b7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import google.genai as genai\n",
    "from google.genai import types\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import typing_extensions as typing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4056fb",
   "metadata": {},
   "source": [
    "### Loading local embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "cc3d58e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded: all-mpnet-base-v2\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding model loaded: all-mpnet-base-v2\")\n",
    "embedder = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e66557",
   "metadata": {},
   "source": [
    "### Constraint JSON schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "68bb88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_schema = {\n",
    "    \"type\": \"OBJECT\",\n",
    "    \"properties\": {\n",
    "        \"category\": {\n",
    "            \"type\": \"STRING\",\n",
    "            \"nullable\": True\n",
    "        },\n",
    "        \"temperature\": {\n",
    "            \"type\": \"STRING\",\n",
    "            \"nullable\": True\n",
    "        },\n",
    "        \"max_calories\": {\n",
    "            \"type\": \"NUMBER\",\n",
    "            \"nullable\": True\n",
    "        },\n",
    "        \"max_sugar\": {\n",
    "            \"type\": \"NUMBER\",\n",
    "            \"nullable\": True\n",
    "        },\n",
    "        \"max_price\": {\n",
    "            \"type\": \"NUMBER\",\n",
    "            \"nullable\": True\n",
    "        },\n",
    "        \"dairy_free\": {\n",
    "            \"type\": \"BOOLEAN\",\n",
    "            \"nullable\": True\n",
    "        },\n",
    "        \"vegan\": {\n",
    "            \"type\": \"BOOLEAN\",\n",
    "            \"nullable\": True\n",
    "        },\n",
    "        \"caffeine_level\": {\n",
    "            \"type\": \"STRING\",\n",
    "            \"nullable\": True\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"category\", \"temperature\", \"max_price\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42b772e",
   "metadata": {},
   "source": [
    "### Loading product data and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "8fefe32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_products = pd.read_csv('data/products.csv')\n",
    "    df_queries = pd.read_csv('data/queries_train.csv') \n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV files not found. Please check your 'data' folder.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7332fd7c",
   "metadata": {},
   "source": [
    "### Pre-computing product embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "28ac25e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating product embeddings...\n",
      "Product embeddings ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating product embeddings...\")\n",
    "cols_to_use = ['name','category','subcategory','temperature','caffeine_mg',\n",
    "               'calories','sugar_g','protein_g','contains_dairy','contains_nuts',\n",
    "               'contains_gluten','is_vegan','description','price']\n",
    "\n",
    "df_products['embedding_text'] = (\n",
    "    df_products[cols_to_use]\n",
    "        .fillna('')\n",
    "        .astype(str)\n",
    "        .agg(' '.join, axis=1)\n",
    ")\n",
    "\n",
    "product_embeddings = embedder.encode(df_products['embedding_text'].tolist())\n",
    "print(\"Product embeddings ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53957d",
   "metadata": {},
   "source": [
    "### Vertex AI initialization/authentication and constraint extraction using prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9fae06d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Project: starbucks-barista-486010\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "import vertexai\n",
    "import warnings\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Authentication\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"auth.json\"\n",
    "\n",
    "# Initialization with Project ID\n",
    "with open(\"auth.json\") as f:\n",
    "    creds = json.load(f)\n",
    "    PROJECT_ID = creds[\"project_id\"]\n",
    "\n",
    "# Initializing Vertex AI with the new project\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "print(f\"Connected to Project: {PROJECT_ID}\")\n",
    "\n",
    "def extract_constraints_gemini(query_text):\n",
    "    try:\n",
    "        model = GenerativeModel(\"gemini-2.5-flash\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are a Starbucks Data Assistant. Extract search constraints from this query:\n",
    "        Query: \"{query_text}\"\n",
    "        \n",
    "        Return a valid JSON object. Use null for missing values.\n",
    "        - category: \"espresso\", \"brewed\", \"cold_brew\", \"frappuccino\", \"refresher\", \"tea\" or null\n",
    "        - temperature: \"hot\", \"iced\", \"blended\" or null\n",
    "        - max_calories: number or null\n",
    "        - max_sugar: number (grams) or null\n",
    "        - max_price: number or null\n",
    "        - dairy_free: true or null\n",
    "        - vegan: true or null\n",
    "        - caffeine_level: \"none\", \"low\", \"medium\", \"high\" or null\n",
    "        Return strictly valid JSON.\n",
    "        Use null (without quotes) for missing values.\n",
    "        Do NOT use 0 unless explicitly stated in the query.\n",
    "        Do NOT return \"null\" as a string.\n",
    "        \"\"\"\n",
    "\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=constraint_schema\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        parsed = json.loads(response.text)\n",
    "        time.sleep(1)\n",
    "        return parsed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        time.sleep(2)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf51f1d8",
   "metadata": {},
   "source": [
    "### Filtering products based on constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "bc48bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_products(products_df, constraints):\n",
    "    \"\"\"\n",
    "    Removes products that violate the specific constraints found by Gemini.\n",
    "    \"\"\"\n",
    "    filtered = products_df.copy()\n",
    "    \n",
    "    if constraints.get('category'):\n",
    "        filtered = filtered[filtered['category'] == constraints['category']]\n",
    "    if constraints.get('temperature'):\n",
    "        filtered = filtered[filtered['temperature'] == constraints['temperature']]\n",
    "        \n",
    "    if constraints.get('max_calories'):\n",
    "        filtered = filtered[filtered['calories'] <= constraints['max_calories']]\n",
    "    if constraints.get('max_sugar'):\n",
    "        filtered = filtered[filtered['sugar_g'] <= constraints['max_sugar']]\n",
    "    if constraints.get('max_price'):\n",
    "        filtered = filtered[filtered['price'] <= constraints['max_price']]\n",
    "        \n",
    "    if constraints.get('dairy_free'):\n",
    "        filtered = filtered[filtered['contains_dairy'] == False]\n",
    "    if constraints.get('vegan'):\n",
    "        filtered = filtered[filtered['is_vegan'] == True]\n",
    "    \n",
    "    if constraints.get('caffeine_level'):\n",
    "        level = constraints['caffeine_level']\n",
    "        if level == \"none\":\n",
    "            filtered = filtered[filtered['caffeine_mg'] == 0]\n",
    "        elif level == 'low':\n",
    "            filtered = filtered[(filtered['caffeine_mg'] > 0) & (filtered['caffeine_mg'] <= 70)]\n",
    "        elif level == 'medium':\n",
    "            filtered = filtered[(filtered['caffeine_mg'] > 70) & (filtered['caffeine_mg'] <= 150)]\n",
    "        elif level == 'high':\n",
    "            filtered = filtered[filtered['caffeine_mg'] > 150]\n",
    "            \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e22594",
   "metadata": {},
   "source": [
    "### Ranking products on Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "037e5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_products(query_text, candidate_df):\n",
    "    \"\"\"\n",
    "    Sorts the remaining products by how similar they are to the user query.\n",
    "    \"\"\"\n",
    "    if candidate_df.empty:\n",
    "        return []\n",
    "    \n",
    "    # User query embedding\n",
    "    query_vec = embedder.encode([query_text])\n",
    "    \n",
    "    # Embedded vectors for valid candidates\n",
    "    candidate_vectors = product_embeddings[candidate_df.index]\n",
    "    \n",
    "    # Similarity score calculation\n",
    "    scores = cosine_similarity(query_vec, candidate_vectors)[0]\n",
    "    \n",
    "    # Attaching scores and sorting\n",
    "    candidate_df = candidate_df.copy()\n",
    "    candidate_df['score'] = scores\n",
    "    ranked = candidate_df.sort_values(by='score', ascending=False)\n",
    "    \n",
    "    return ranked['product_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58254e73",
   "metadata": {},
   "source": [
    "### Main execution loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8e15fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:16<00:00,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Extracted!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_001</td>\n",
       "      <td>ICE_007;ESP_013;ICE_009;ICE_008;ICE_015;ESP_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_002</td>\n",
       "      <td>TEA_011;TEA_005;TEA_010;TEA_008;ICT_010;ICT_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_003</td>\n",
       "      <td>BRW_004;BRW_005;BRW_003;BRW_002;BRW_001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_004</td>\n",
       "      <td>TEA_005;TEA_012;TEA_008;ICT_002;ICT_004;ICT_00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_005</td>\n",
       "      <td>CBR_012;CBR_011;CBR_002;CBR_001;CBR_009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id                                           products\n",
       "0  TRAIN_001  ICE_007;ESP_013;ICE_009;ICE_008;ICE_015;ESP_00...\n",
       "1  TRAIN_002  TEA_011;TEA_005;TEA_010;TEA_008;ICT_010;ICT_00...\n",
       "2  TRAIN_003            BRW_004;BRW_005;BRW_003;BRW_002;BRW_001\n",
       "3  TRAIN_004  TEA_005;TEA_012;TEA_008;ICT_002;ICT_004;ICT_00...\n",
       "4  TRAIN_005            CBR_012;CBR_011;CBR_002;CBR_001;CBR_009"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "print(f\"Processing {len(df_queries)} queries...\")\n",
    "\n",
    "for i, row in tqdm(df_queries.iterrows(), total=len(df_queries)):\n",
    "    q_id = row['query_id']\n",
    "    q_text = row['query_text']\n",
    "    \n",
    "    constraints = extract_constraints_gemini(q_text)\n",
    "    \n",
    "    # Filtering\n",
    "    if constraints:\n",
    "        candidates = filter_products(df_products, constraints)\n",
    "    else:\n",
    "        candidates = df_products\n",
    "    \n",
    "    if candidates.empty:\n",
    "        candidates = df_products\n",
    "        \n",
    "    # Ranking\n",
    "    ranked_ids = rank_products(q_text, candidates)\n",
    "    \n",
    "    # Saving results\n",
    "    results.append({\n",
    "        \"query_id\": q_id,\n",
    "        \"products\": \";\".join(ranked_ids)\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"Results Extracted!\")\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b7f3e2",
   "metadata": {},
   "source": [
    "### Evaluation of results (Recall & NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "d6d1cae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True product list detected. Calculating NDCG, Recall, and Accuracy.\n",
      "\n",
      "========================================\n",
      " Pipeline Performance Report\n",
      "========================================\n",
      "Average NDCG:      0.9650\n",
      "Average Recall:    0.9770\n",
      "Top-1 Accuracy:    0.9700\n",
      "========================================\n",
      "\n",
      "Detailed evaluation saved to output/training_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "if 'relevant_products' in df_queries.columns:\n",
    "    print(\"True product list detected. Calculating NDCG, Recall, and Accuracy.\")\n",
    "    \n",
    "    df_eval = pd.merge(df_queries[['query_id', 'relevant_products']], df_results, on='query_id')\n",
    "\n",
    "    # NDCG calculation function\n",
    "    def get_ndcg(row):\n",
    "        pred_str = row['products']\n",
    "        truth_str = row['relevant_products']\n",
    "        \n",
    "        if pd.isna(pred_str) or not pred_str: return 0.0\n",
    "        \n",
    "        predicted_list = pred_str.split(';')\n",
    "    \n",
    "        try:\n",
    "            truth_list = ast.literal_eval(truth_str)\n",
    "        except:\n",
    "            return 0.0\n",
    "     \n",
    "        dcg = sum(1.0 / np.log2(i + 2) for i, p in enumerate(predicted_list) if p in truth_list)\n",
    "        \n",
    "        idcg = sum(1.0 / np.log2(i + 2) for i in range(len(truth_list)))\n",
    "        \n",
    "        return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "    # Recall & Precision at rank function\n",
    "    def get_recall_and_accuracy(row):\n",
    "        pred_str = row['products']\n",
    "        truth_str = row['relevant_products']\n",
    "        \n",
    "        if pd.isna(pred_str) or not pred_str:\n",
    "            return pd.Series({'recall': 0.0, 'top_1_accuracy': 0.0})\n",
    "            \n",
    "        predicted_list = pred_str.split(';')\n",
    "        \n",
    "        try:\n",
    "            truth_list = ast.literal_eval(truth_str)\n",
    "        except:\n",
    "            truth_list = []\n",
    "            \n",
    "        set_pred = set(predicted_list)\n",
    "        set_truth = set(truth_list)\n",
    "        \n",
    "        intersection = set_pred.intersection(set_truth)\n",
    "       \n",
    "        recall = len(intersection) / len(set_truth) if set_truth else 0.0\n",
    "      \n",
    "        top_1 = 1.0 if (predicted_list and predicted_list[0] in set_truth) else 0.0\n",
    "        \n",
    "        return pd.Series({'recall': recall, 'top_1_accuracy': top_1})\n",
    "\n",
    "    df_eval['ndcg'] = df_eval.apply(get_ndcg, axis=1)\n",
    "    df_eval[['recall', 'top_1_accuracy']] = df_eval.apply(get_recall_and_accuracy, axis=1)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\" Pipeline Performance Report\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Average NDCG:      {df_eval['ndcg'].mean():.4f}\")\n",
    "    print(f\"Average Recall:    {df_eval['recall'].mean():.4f}\")\n",
    "    print(f\"Top-1 Accuracy:    {df_eval['top_1_accuracy'].mean():.4f}\")\n",
    "    print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "    df_eval.to_csv('output/training_evaluation.csv', index=False)\n",
    "    print(\"Detailed evaluation saved to output/training_evaluation.csv\")\n",
    "\n",
    "else:\n",
    "    # If no true labels, saving predictions (for test set)\n",
    "    df_results.to_csv('output/submission.csv', index=False)\n",
    "    print(\"Test submission saved to output/submission.csv. Ready to upload!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4888446",
   "metadata": {},
   "source": [
    "### Saving final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c353d6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to output/submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame(results)\n",
    "submission.to_csv('output/submission.csv', index=False)\n",
    "print(\"File saved to output/submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a451fc97",
   "metadata": {},
   "source": [
    "## Tuning Code & Testing On Single Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "74047e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating product embeddings...\n",
      "Product embeddings ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating product embeddings...\")\n",
    "df_products_copy = df_products.copy()\n",
    "cols_to_use = ['name','category','subcategory','temperature','caffeine_mg',\n",
    "               'calories','sugar_g','protein_g','contains_dairy','contains_nuts',\n",
    "               'contains_gluten','is_vegan','description','price']\n",
    "\n",
    "df_products_copy['embedding_text'] = (\n",
    "    df_products_copy[cols_to_use]\n",
    "        .fillna('')\n",
    "        .astype(str)\n",
    "        .agg(' '.join, axis=1)\n",
    ")\n",
    "\n",
    "product_embeddings_1 = embedder.encode(df_products_copy['embedding_text'].tolist())\n",
    "print(\"Product embeddings ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "9bb46dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_019</td>\n",
       "      <td>REF_001;REF_008;REF_002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id                 products\n",
       "0  TRAIN_019  REF_001;REF_008;REF_002"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1 = []\n",
    "\n",
    "\n",
    "q_id_1 = 'TRAIN_019'\n",
    "q_text_1 = \"running late but i need something refreshing and fruity that's no more than 150 cal and no more than $4.5\"\n",
    "\n",
    "constraints_1 = extract_constraints_gemini(q_text_1)\n",
    "\n",
    "if constraints_1:\n",
    "    candidates_1 = filter_products(df_products, constraints_1)\n",
    "else:\n",
    "    candidates_1 = df_products\n",
    "\n",
    "if candidates_1.empty:\n",
    "    candidates_1 = df_products\n",
    "\n",
    "ranked_ids_1 = rank_products(q_text_1, candidates_1)\n",
    "\n",
    "results_1.append({\n",
    "    \"query_id\": q_id_1,\n",
    "    \"products\": \";\".join(ranked_ids_1)\n",
    "})\n",
    "\n",
    "df_results_1 = pd.DataFrame(results_1)\n",
    "print(\"Done!\")\n",
    "df_results_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "2636ff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>temperature</th>\n",
       "      <th>caffeine_mg</th>\n",
       "      <th>calories</th>\n",
       "      <th>sugar_g</th>\n",
       "      <th>protein_g</th>\n",
       "      <th>contains_dairy</th>\n",
       "      <th>contains_nuts</th>\n",
       "      <th>contains_gluten</th>\n",
       "      <th>is_vegan</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>embedding_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>REF_001</td>\n",
       "      <td>Strawberry Acai Refresher</td>\n",
       "      <td>refresher</td>\n",
       "      <td>water</td>\n",
       "      <td>iced</td>\n",
       "      <td>45</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Sweet strawberry and acai flavors with real fr...</td>\n",
       "      <td>4.45</td>\n",
       "      <td>Strawberry Acai Refresher refresher water iced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>REF_002</td>\n",
       "      <td>Mango Dragonfruit Refresher</td>\n",
       "      <td>refresher</td>\n",
       "      <td>water</td>\n",
       "      <td>iced</td>\n",
       "      <td>45</td>\n",
       "      <td>90</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Mango and dragonfruit flavors with real fruit ...</td>\n",
       "      <td>4.45</td>\n",
       "      <td>Mango Dragonfruit Refresher refresher water ic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>REF_008</td>\n",
       "      <td>Pineapple Passionfruit Refresher</td>\n",
       "      <td>refresher</td>\n",
       "      <td>water</td>\n",
       "      <td>iced</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Tropical pineapple and passionfruit flavors</td>\n",
       "      <td>4.45</td>\n",
       "      <td>Pineapple Passionfruit Refresher refresher wat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                              name   category subcategory  \\\n",
       "80    REF_001         Strawberry Acai Refresher  refresher       water   \n",
       "81    REF_002       Mango Dragonfruit Refresher  refresher       water   \n",
       "87    REF_008  Pineapple Passionfruit Refresher  refresher       water   \n",
       "\n",
       "   temperature  caffeine_mg  calories  sugar_g  protein_g  contains_dairy  \\\n",
       "80        iced           45        90       20          0           False   \n",
       "81        iced           45        90       19          1           False   \n",
       "87        iced           45       100       22          0           False   \n",
       "\n",
       "    contains_nuts  contains_gluten  is_vegan  \\\n",
       "80          False            False      True   \n",
       "81          False            False      True   \n",
       "87          False            False      True   \n",
       "\n",
       "                                          description  price  \\\n",
       "80  Sweet strawberry and acai flavors with real fr...   4.45   \n",
       "81  Mango and dragonfruit flavors with real fruit ...   4.45   \n",
       "87        Tropical pineapple and passionfruit flavors   4.45   \n",
       "\n",
       "                                       embedding_text  \n",
       "80  Strawberry Acai Refresher refresher water iced...  \n",
       "81  Mango Dragonfruit Refresher refresher water ic...  \n",
       "87  Pineapple Passionfruit Refresher refresher wat...  "
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "82e1e252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "0dddda49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([80, 81, 87], dtype='int64')"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1d2ffe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'refresher', 'temperature': 'iced', 'max_calories': 150, 'max_sugar': None, 'max_price': 4.5, 'dairy_free': None, 'vegan': None, 'caffeine_level': None}\n"
     ]
    }
   ],
   "source": [
    "print(constraints_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f4707c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "qvec = embedder.encode([q_text_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "016297da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "9982f0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"running late but i need something refreshing and fruity that's no more than 150 cal and no more than $4.5\""
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "d1b7e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_vectors = product_embeddings_1[candidates_1.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d638ce66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 768)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "81df1edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5859856 , 0.51825416, 0.545011  ], dtype=float32)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 = cosine_similarity(qvec, cand_vectors)[0]\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "77097c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>temperature</th>\n",
       "      <th>caffeine_mg</th>\n",
       "      <th>calories</th>\n",
       "      <th>sugar_g</th>\n",
       "      <th>protein_g</th>\n",
       "      <th>contains_dairy</th>\n",
       "      <th>contains_nuts</th>\n",
       "      <th>contains_gluten</th>\n",
       "      <th>is_vegan</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>embedding_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>REF_001</td>\n",
       "      <td>Strawberry Acai Refresher</td>\n",
       "      <td>refresher</td>\n",
       "      <td>water</td>\n",
       "      <td>iced</td>\n",
       "      <td>45</td>\n",
       "      <td>90</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Sweet strawberry and acai flavors with real fr...</td>\n",
       "      <td>4.45</td>\n",
       "      <td>Strawberry Acai Refresher refresher water iced...</td>\n",
       "      <td>0.585986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>REF_008</td>\n",
       "      <td>Pineapple Passionfruit Refresher</td>\n",
       "      <td>refresher</td>\n",
       "      <td>water</td>\n",
       "      <td>iced</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Tropical pineapple and passionfruit flavors</td>\n",
       "      <td>4.45</td>\n",
       "      <td>Pineapple Passionfruit Refresher refresher wat...</td>\n",
       "      <td>0.545011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>REF_002</td>\n",
       "      <td>Mango Dragonfruit Refresher</td>\n",
       "      <td>refresher</td>\n",
       "      <td>water</td>\n",
       "      <td>iced</td>\n",
       "      <td>45</td>\n",
       "      <td>90</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Mango and dragonfruit flavors with real fruit ...</td>\n",
       "      <td>4.45</td>\n",
       "      <td>Mango Dragonfruit Refresher refresher water ic...</td>\n",
       "      <td>0.518254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                              name   category subcategory  \\\n",
       "80    REF_001         Strawberry Acai Refresher  refresher       water   \n",
       "87    REF_008  Pineapple Passionfruit Refresher  refresher       water   \n",
       "81    REF_002       Mango Dragonfruit Refresher  refresher       water   \n",
       "\n",
       "   temperature  caffeine_mg  calories  sugar_g  protein_g  contains_dairy  \\\n",
       "80        iced           45        90       20          0           False   \n",
       "87        iced           45       100       22          0           False   \n",
       "81        iced           45        90       19          1           False   \n",
       "\n",
       "    contains_nuts  contains_gluten  is_vegan  \\\n",
       "80          False            False      True   \n",
       "87          False            False      True   \n",
       "81          False            False      True   \n",
       "\n",
       "                                          description  price  \\\n",
       "80  Sweet strawberry and acai flavors with real fr...   4.45   \n",
       "87        Tropical pineapple and passionfruit flavors   4.45   \n",
       "81  Mango and dragonfruit flavors with real fruit ...   4.45   \n",
       "\n",
       "                                       embedding_text     score  \n",
       "80  Strawberry Acai Refresher refresher water iced...  0.585986  \n",
       "87  Pineapple Passionfruit Refresher refresher wat...  0.545011  \n",
       "81  Mango Dragonfruit Refresher refresher water ic...  0.518254  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_1_copy = candidates_1.copy()\n",
    "candidates_1_copy['score'] = score1\n",
    "ranked1 = candidates_1_copy.sort_values(by='score', ascending=False)\n",
    "ranked1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
